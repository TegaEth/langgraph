{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CEREBRAS_API_KEY=os.getenv('CEREBRAS_API_KEY')\n",
    "TAVILY_API_KEY=os.getenv('TAVILY_API_KEY')\n",
    "LANGSMITH_API_KEY = os.getenv('LANGSMITH_API_KEY')\n",
    "LANGSMITH_TRACING=os.getenv('LANGSMITH_TRACING')\n",
    "LANGSMITH_ENDPOINT=os.getenv('LANGSMITH_ENDPOINT')\n",
    "LANGSMITH_API_KEY=os.getenv('LANGSMITH_API_KEY')\n",
    "LANGSMITH_PROJECT=os.getenv('LANGSMITH_PROJECT')\n",
    "TAVILY_API_KEY=os.getenv('TAVILY_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CEREBRAS_API_KEY'] = CEREBRAS_API_KEY\n",
    "os.environ['TAVILY_API_KEY'] = TAVILY_API_KEY\n",
    "os.environ['LANGSMITH_API_KEY'] = LANGSMITH_API_KEY\n",
    "os.environ['LANGSMITH_TRACING'] = \"true\"\n",
    "os.environ['LANGSMITH_ENDPOINT'] = \"https://api.smith.langchain.com\"\n",
    "os.environ['LANGSMITH_PROJECT'] = LANGSMITH_PROJECT\n",
    "os.environ['TAVILY_API_KEY'] = TAVILY_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_cerebras import ChatCerebras\n",
    "\n",
    "llm = ChatCerebras(\n",
    "    model=\"llama-3.3-70b\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sentence_transformers import SentenceTransformer\n",
    "# embedding = SentenceTransformer('sentence-transformers/multi-qa-MiniLM-L6-cos-v1')\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# Wrapping the SentenceTransformer with LangChain-compatible embedding\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/multi-qa-MiniLM-L6-cos-v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predefine Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: LangChain\n",
      "Summary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\n",
      "\n",
      "\n",
      "\n",
      "Page: Retrieval-augmented generation\n",
      "Summary: Retrieval-augmented generation (RAG) is a technique that enables generative artificial intelligence (Gen AI) models to retrieve and incorporate new information. It modifies interactions with a large language model (LLM) so that the model responds to user queries with reference to a specified set of documents, using this information to supplement information from its pre-existing training data. This allows LLMs to use domain-specific and/or updated information. Use cases include providing chatbot access to internal company data or generating responses based on authoritative sources.\n",
      "RAG improves large language models (LLMs) by incorporating information retrieval before generating responses. Unlike traditional LLMs that rely on static training data, RAG pulls relevant text from databases, uploaded documents, or web sources. According to Ars Technica, \"RAG is a way of improving LLM performance, in essence by blending the LLM process with a web search or other document look-up process to help LLMs stick to the facts.\" This method helps reduce AI hallucinations, which have led to real-world issues like chatbots inventing policies or lawyers citing nonexistent legal cases.\n",
      "By dynamically retrieving information, RAG enables AI to provide more accurate responses without frequent retraining. According to IBM, \"RAG also reduces the need for users to continuously train the model on new data and update its parameters as circumstances evolve. In this way, RAG can lower the computational and financial costs of running LLM-powered chatbots in an enterprise setting.\"\n",
      "Beyond efficiency gains, RAG also allows LLMs to include source references in their responses, enabling users to verify information by reviewing cited documents or original sources. This can provide greater transparency, as users can cross-check retrieved content to ensure accuracy and relevance.\n",
      "The term RAG was first introduced in 2020 by Douwe Kiela, Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, and Sebastian Riedel in their research paper Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks, at Meta.\n",
      "\n",
      "Page: Milvus (vector database)\n",
      "Summary: Milvus is a distributed vector database developed by Zilliz. It is available as both open-source software and a cloud service.\n",
      "Milvus is an open-source project under LF AI & Data Foundation distributed under the Apache License 2.0.\n"
     ]
    }
   ],
   "source": [
    "api_wrapper = WikipediaAPIWrapper()\n",
    "tool = WikipediaQueryRun(api_wrapper=api_wrapper)\n",
    "print(tool.run({'query':'langchain'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Ochi | Wookieepedia - Fandom',\n",
       "  'url': 'https://starwars.fandom.com/wiki/Ochi',\n",
       "  'content': \"Ochi was a Bestoonian male assassin and cultist of the Sith known as Ochi of Bestoon, hailing from the world of the same name with a career spanning decades, from the twilight of the Galactic Republic, and the subsequent rise of the Galactic Empire to the era of the New Republic. Ochi possessed a personal Sith dagger used to commit acts of murder, and had head implants. Trained in combat and martial skills, Ochi was a very capable fighter and lent his services to the Sith Lords Darth Sidious [...] During the Imperial Era, Ochi was an associate of advisor Yupe Tashu and was employed as an assassin by both the Emperor, Darth Sidious, and his right-hand, Darth Vader. Ochi also took part in the auction of Han Solo and became an undercover operative of Lady Qi'ra and Crimson Dawn following the Battle of Hoth at the height of the Galactic Civil War. [...] By this time, Ochi's bones had been picked clean by gouge-beetles.[13] Unlike Ochi, however, Rey and the others escaped the caves, and Rey sought justice for her parents. After Rey left the others behind on Kef Bir, D-O stated that he missed her. Finn asked the droid his name, but then learned that D-O had a lot of information on Exegol, which was Ochi's intended destination before his death.[7]\\n\\nPersonality and traits[]\\n\\nOchi was a devoted Sith assassin and Jedi hunter.\",\n",
       "  'score': 0.78944516},\n",
       " {'title': 'Ochi | Disney Wiki - Fandom',\n",
       "  'url': 'https://disney.fandom.com/wiki/Ochi',\n",
       "  'content': \"Ochi, also known as Ochi of Bestoon, is a recurring antagonist in the Star Wars franchise.\\n\\nContents\\n\\nBackground[] [...] Ochi was born on the planet Bestoon. He was a known Jedi hunter since the Clone Wars and became an assassin obsessed with finding Sith relics. At some point, he obtained the droid D-O from one of his victims. Shadow of the Sith, reveals he abused the droid and he was reactivated by the Sith. He owned a  modified WTK-85A interstellar transport called the Bestoon Legacy, which was left with D-O on Pasaana after the Sith assassin's demise there. Ochi also possessed a personal Sith dagger used to [...] Ochi\\n\\nOchi\\n\\nBackground information\\n\\nFeature films\\nStar Wars: The Rise of Skywalker\\n\\n\\nPortrayed by\\nLiam Cook\\n\\n\\n\\nCharacter information\\n\\nFull name\\nOchi\\n\\n\\nOther names\\nOchi of Bestoon\\n\\n\\nOccupation\\nMaster Assassin in the Assassin's GuildMember of the Acolytes of BeyondSith Assassin of the Sith EternalAgent and Spy of the Crimson Dawn (formerly)\\n\\n\\nAffiliations\\nAssassin's GuildAcolytes of BeyondSith OrderSith EternalCrimson Dawn (formerly)\\n\\n\\nHome\\nBestoon\",\n",
       "  'score': 0.75442725},\n",
       " {'title': 'Ochi Ojie (@bunchiochi_) • Instagram photos and videos',\n",
       "  'url': 'https://www.instagram.com/bunchiochi_/reels/',\n",
       "  'content': '2521 Followers, 5737 Following, 7 Posts - Ochi Ojie (@bunchiochi_) on Instagram: \"CoFounder, CTO of FBA Finance. Software Engineer\"',\n",
       "  'score': 0.7253574},\n",
       " {'title': 'Ochi Ojie (@bunchiochi_) • Instagram photos and videos',\n",
       "  'url': 'https://www.instagram.com/bunchiochi_/',\n",
       "  'content': '2363 Followers, 6331 Following, 12 Posts - Ochi Ojie (@bunchiochi_) on Instagram: \"CoFounder, CTO of FBA Finance. Software Engineer\"',\n",
       "  'score': 0.7244226},\n",
       " {'title': 'Ochi Ojie - Facebook',\n",
       "  'url': 'https://m.facebook.com/ochi.ojie.9/',\n",
       "  'content': 'I am just a brilliant guy with a wild imagination. . Chief executive officer at Self-Employed. . Studied Mechatronics & Robotics Engineering at Harvard',\n",
       "  'score': 0.65914243}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "tool = TavilySearchResults()\n",
    "tool.invoke({'query': 'Who is Ochi Ojie'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a custom tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool\n",
    "\n",
    "@tool\n",
    "def get_word_length("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
